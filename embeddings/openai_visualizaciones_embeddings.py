# -*- coding: utf-8 -*-
"""openai_visualizaciones-embeddings.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IRgXU8LqkrmN7olnULJHJllvasmA58hf

## Visualizando embeddings
"""

!pip install google-cloud-secret-manager google-auth google-auth-oauthlib openai mplcursors

"""#### Detalles del proyecto"""

import openai
from openai import OpenAI
from google.cloud import secretmanager
from google.colab import auth
auth.authenticate_user()
from google.colab import userdata
# Creamos un Cliente de SecretManager:
client = secretmanager.SecretManagerServiceClient()
secret_name = userdata.get('SECRET_NAME') # => Cambia por el nombre de tu secreto (en google cloud secret manager)
project_id = userdata.get('PROJECT_ID')
# Construye un F-string con los datos:
resource_name = f"projects/{project_id}/secrets/{secret_name}/versions/latest"

# REcupera tu secreto :
response = client.access_secret_version(request={"name": resource_name})
secret_string = response.payload.data.decode('UTF-8')

# Tu clave secreta queda bajo secret_string

# Configurar el motor de OpenAI
engine = "gpt-4-1106-preview"
client = OpenAI(api_key=secret_string)

def get_completion(prompt):
  completion = client.chat.completions.create(
  model=engine,
  messages=[
      {"role": "system", "content": "Eres un asistente, que realizas resúmenes concisos y proporcionas la ideas principales de un texto."},
      {"role": "user", "content": f"{prompt}"}
    ]
  )
  return completion

def get_embedding(text):
    response = client.embeddings.create(
        model="text-embedding-ada-002",
        input=text
    )
    # Obtener el embedding del primer elemento de la respuesta
    embedding = response.data[0].embedding
    return embedding

# Utilizar la función
texto = "jaguar"
embedding = get_embedding(texto)
print(embedding[:10])

"""## Capturando significado con embeddings"""

in_1 = "Hemos observado un ibis volando hacia la laguna"

in_2 = "Avistada una nutria en la costa"

in_3 = "Un perro parece divertirse con los delfines"


in_4 = "La ensalada de aguacate está deliciosa!"

in_5 = "Me encanta la comida japonesa!"


in_6 = "Los programadores de Python son gente genial"

in_7 = "TypeScript, C++ o Java? Todos molan!"


input_text_lst_news = [in_1, in_2, in_3, in_4, in_5, in_6, in_7]

import numpy as np

"""- Obtenemos embeddings para todas las piezas de texto.
- Las almacenamos en un array NumPy 2D (una fila por cada embedding).
"""

embeddings = []
for input_text in input_text_lst_news:
    emb = get_embedding(input_text)
    embeddings.append(emb)

embeddings_array = np.array(embeddings)

print("Shape: " + str(embeddings_array.shape))
print(embeddings_array)

"""#### Reducimos de 768 a 2 dimensiones para visualizar
- Usamos principal component analysis (PCA).

"""

from sklearn.decomposition import PCA

# Hacemos PCA para 2D
PCA_model = PCA(n_components = 2)
PCA_model.fit(embeddings_array)
dosD_values = PCA_model.transform(embeddings_array)

print("Shape: " + str(dosD_values.shape))
print(dosD_values)

import matplotlib.pyplot as plt
import mplcursors
def plot_2D(x_values, y_values, labels):

    # Creamos scatter plot
    fig, ax = plt.subplots()
    scatter = ax.scatter(x_values,
                         y_values,
                         alpha = 0.5,
                         edgecolors='k',
                         s = 40)

    # Creamos a mplcursors object to manage the data point interaction
    cursor = mplcursors.cursor(scatter, hover=True)

    #aes
    ax.set_title('Visualización del embedding en 2D')
    ax.set_xlabel('X_1')  # Add x-axis label
    ax.set_ylabel('X_2')  # Add y-axis label

    # Define how each annotation should look
    @cursor.connect("add")
    def on_add(sel):
        sel.annotation.set_text(labels[sel.target.index])
        sel.annotation.get_bbox_patch().set(facecolor='white', alpha=0.5) # Set annotation's background color
        sel.annotation.set_fontsize(12)

    plt.show()


plot_2D(dosD_values[:,0], dosD_values[:,1], input_text_lst_news)

# Perform PCA for 3D visualization
PCA_model = PCA(n_components = 3)
PCA_model.fit(embeddings_array)
embeddings_3d = PCA_model.transform(embeddings_array)

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

fig = plt.figure(figsize=(10, 7))
ax = fig.add_subplot(111, projection='3d')

# Supongamos que embeddings_3d es tu matriz de embeddings reducida a 3 dimensiones
x, y, z = embeddings_3d[:,0], embeddings_3d[:,1], embeddings_3d[:,2]
ax.scatter(x, y, z)

# Etiquetar los ejes (opcional)
ax.set_xlabel('Componente 1')
ax.set_ylabel('Componente 2')
ax.set_zlabel('Componente 3')

plt.show()

from sklearn.metrics.pairwise import cosine_similarity

def compare(embeddings,idx1,idx2):
    return cosine_similarity([embeddings[idx1]],[embeddings[idx2]])

print(in_1)
print(in_2)
print(compare(embeddings,0,1))

print(in_1)
print(in_4)
print(compare(embeddings,0,3))