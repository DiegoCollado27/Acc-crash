{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jxxfdcy_qA4"
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors\n",
        "import os\n",
        "\n",
        "# Cargar el modelo GloVe (Asegúrate de ajustar la ruta al archivo GloVe)\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "#glove_input_file = glove_filename\n",
        "word2vec_file = 'drive/MyDrive/Colab Notebooks/data/glove.6B.100d.txt'\n",
        "model_file = 'drive/MyDrive/Colab Notebooks/data/glove_model'\n",
        "if os.path.exists(model_file):\n",
        "    model = KeyedVectors.load(model_file)\n",
        "else:\n",
        "    try:\n",
        "        model = KeyedVectors.load_word2vec_format(word2vec_file, binary=False, no_header=True)\n",
        "        model.save(model_file)\n",
        "    except:\n",
        "        print('No encuentro el modelo')\n",
        "\n",
        "# Realizar la operación vectorial\n",
        "mother_prueba = model['father'] - model['man'] + model['woman']\n",
        "\n",
        "# Encontrar las palabras más cercanas al vector resultante\n",
        "palabras_mas_similares = model.similar_by_vector(mother_prueba)\n",
        "\n",
        "print(\"Las palabras más similares son:\")\n",
        "for word, similaridad in palabras_mas_similares:\n",
        "    print(f\"{word}: {similaridad}\")\n",
        "\n",
        "#print('king: ',model.get_vector('king'))\n",
        "\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "\n",
        "print('Palabras más similares para King + Woman - Man: ', result)\n",
        "\n",
        "frase = model.most_similar(positive=['the', 'man', 'that', 'rules', 'boss'])\n",
        "print('Palabras más similares para frase: ', frase)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# 1. Selección de Palabras\n",
        "palabras = ['king', 'queen', 'man', 'woman', 'prince', 'princess', 'tiger', 'lion', 'monkey', 'tree']\n",
        "\n",
        "# 2. Extracción de Vectores\n",
        "vectores = [model[word] for word in palabras]\n",
        "\n",
        "# 3. Reducción de Dimensionalidad\n",
        "pca = PCA(n_components=2)\n",
        "vectores_reducidos = pca.fit_transform(vectores)\n",
        "\n",
        "# 4. Visualización\n",
        "plt.figure(figsize=(10, 8))\n",
        "for palabra, vector in zip(palabras, vectores_reducidos):\n",
        "    plt.scatter(vector[0], vector[1])\n",
        "    plt.text(vector[0] + 0.05, vector[1] + 0.05, palabra)\n",
        "\n",
        "plt.title('Representación 2D de Palabras en el Espacio Vectorial')\n",
        "plt.xlabel('Componente Principal 1')\n",
        "plt.ylabel('Componente Principal 2')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Kw1niOpIKSSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=3)  # Cambia n_components a 3 para reducir a 3 dimensiones\n",
        "vectores_reducidos = pca.fit_transform(vectores)\n",
        "\n",
        "# 4. Visualización en 3D\n",
        "fig = plt.figure(figsize=(12, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')  # Configura el subplot para 3D\n",
        "\n",
        "# Descompone los vectores reducidos en sus tres componentes\n",
        "x = vectores_reducidos[:, 0]\n",
        "y = vectores_reducidos[:, 1]\n",
        "z = vectores_reducidos[:, 2]\n",
        "\n",
        "ax.scatter(x, y, z, depthshade=True, s=50)  # Dibuja los puntos en 3D\n",
        "\n",
        "# Etiqueta cada punto con su palabra correspondiente\n",
        "for i, palabra in enumerate(palabras):\n",
        "    ax.text(x[i], y[i], z[i], palabra)\n",
        "\n",
        "ax.set_title('Representación 3D de Palabras en el Espacio Vectorial')\n",
        "ax.set_xlabel('Componente Principal 1')\n",
        "ax.set_ylabel('Componente Principal 2')\n",
        "ax.set_zlabel('Componente Principal 3')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S6Wu2KtcLv83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usando tokenizador y frase"
      ],
      "metadata": {
        "id": "PSKK1u36MREZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Frases a analizar\n",
        "frases = [\"A dragon lives in a deep cave near the village\",\n",
        "          \"In a hole in the ground there lived a hobbit.\"]\n",
        "\n",
        "# calcular el vector promedio de una frase\n",
        "def vector_promedio_frase(frase, modelo):\n",
        "    # Tokenización simple por espacios\n",
        "\n",
        "    palabras = frase.lower().split()\n",
        "    vectores = []\n",
        "\n",
        "    for palabra in palabras:\n",
        "        if palabra not in stop_words:  # Filtra stopwords\n",
        "            try:\n",
        "                vectores.append(modelo[palabra])\n",
        "            except KeyError:\n",
        "                # Si la palabra no está en el modelo, la omitimos\n",
        "                continue\n",
        "\n",
        "    # Si no se encontraron vectores válidos, regresa un vector de ceros\n",
        "    if len(vectores) == 0:\n",
        "        return np.zeros(modelo.vector_size)\n",
        "\n",
        "    # Calcula el promedio de los vectores\n",
        "    vector_promedio = np.mean(vectores, axis=0)\n",
        "    return vector_promedio\n",
        "\n",
        "# Calcular vectores promedio para cada frase\n",
        "vectores_promedio_frases = [vector_promedio_frase(frase, model) for frase in frases]\n",
        "\n",
        "# Ahora, para demostración, buscar palabras similares al vector promedio de cada frase\n",
        "for i, vector in enumerate(vectores_promedio_frases):\n",
        "    palabras_mas_similares = model.similar_by_vector(vector)\n",
        "    print(f\"Palabras más similares a la frase {i+1}:\")\n",
        "    for palabra, similaridad in palabras_mas_similares:\n",
        "        print(f\"{palabra}: {similaridad}\")\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "id": "OGEQEk12MC1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}