{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai langchain-openai google-cloud-secret-manager scipy datasets"
      ],
      "metadata": {
        "id": "nJ72Nu_FYhOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwKvgFzo_Uk_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from transformers import pipeline\n",
        "import scipy\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import OpenAI\n",
        "import torch\n",
        "from IPython.display import Image\n",
        "from datasets import load_dataset\n",
        "from google.colab import userdata\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "secret_string = userdata.get('OPENAI_TOKEN')\n",
        "\n",
        "llm = OpenAI(openai_api_key=secret_string, temperature=1)\n",
        "\n",
        "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\", max_new_tokens=20)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "\n",
        "def image2text(image):\n",
        "    text_result = captioner(image)\n",
        "    return text_result[0]['generated_text']\n",
        "\n",
        "def crear_historia(topic):\n",
        "   template = \"\"\"\n",
        "   You are a writer and story teller.\n",
        "   Your task is generate short stories from a shrot description. The story cannot have more than 50 words.\n",
        "   CONTEXT: {topic}\n",
        "   STORY:\n",
        "   \"\"\"\n",
        "   topic_template = PromptTemplate(template=template, input_variables=['topic'])\n",
        "\n",
        "   chain = ({\"topic\": RunnablePassthrough()} | topic_template | llm | parser)\n",
        "   response = chain.invoke(topic)\n",
        "   return response\n",
        "\n",
        "def crear_audio(text):\n",
        "  synthesiser = pipeline(\"text-to-speech\", model=\"microsoft/speecht5_tts\")\n",
        "  embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
        "  speaker_embedding = torch.tensor(embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
        "\n",
        "  speech = synthesiser(f\"{text}\", forward_params={\"speaker_embeddings\": speaker_embedding})\n",
        "\n",
        "  scipy.io.wavfile.write(\"historia.wav\", rate=speech[\"sampling_rate\"], data=speech[\"audio\"])\n",
        "\n",
        "generated_topic = image2text(\"https://img.freepik.com/premium-photo/dark-mansion-with-lights-forest_839169-21855.jpg\")\n",
        "\n",
        "historia = crear_historia(generated_topic)\n",
        "crear_audio(historia)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "POWtrkbBJh9P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}