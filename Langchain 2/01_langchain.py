# -*- coding: utf-8 -*-
"""01 - Langchain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oGJJHmIILpp0gaTU8rpXSxy-i8XeOPNX
"""

# Si no tenemos el módulo instalado
# !pip install google-cloud-secret-manager
!pip install langchain langchain-openai

"""### LangChain: Modelos, Prompts and Parsers de salida

"""

# Primero autenticamos el usuario :
import sys
from google.colab import userdata
openai_token = userdata.get('OPENAI_TOKEN')

from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

engine = "gpt-4"

model = ChatOpenAI(temperature=0.7, model=engine,openai_api_key=openai_token)

"""## Plantilla de Prompt"""

estilo_formal = """Español Castellano \
correcto, educado y conciliador
"""

plantilla = """Transforma el texto \
delimitado por acento grave triple \
en un texto con el estilo {estilo}. \
text: ```{texto}```
"""

from langchain.prompts import ChatPromptTemplate

prompt_template = ChatPromptTemplate.from_template(plantilla)
print(prompt_template.messages[0].prompt)
print(prompt_template.messages[0].prompt.input_variables)

texto_original = """
Bueno, la verdad es que paso bastante de los resultados.
Me importa un bledo lo que piensen en dirección. La próxima vez que me contacten
para hablar de esto, les voy a mandar al carajo!
"""

messages = {
    "estilo": estilo_formal,
    "texto": texto_original
}

###Llamamos al LLM para transformar el mensaje según la plantilla
chain = prompt_template | model | StrOutputParser()
response = chain.invoke(messages)
response

"""### Procesador de salida (output parsers)
Ayudan a transformar la salida cruda del modelo en algo más utilizable o en un formato específico que sea más fácil de manejar en la aplicación donde se utiliza el modelo.
"""

{
  "difícil": False,
  "material": "Muy bueno!",
  "calidad_precio": "buena relación calidad-precio"
}

valoracion = """\
Me ha gustado mucho el curso. El material ha sido extenso e interesante.
A pesar de ello, era la primera vez que estudiaba estos conceptos
y me costó un poco asimilarlos.
Estoy muy contento con haber hecho esta inversión de dinero en mi conocimiento.
Lo recomendaré a otros colegas de trabajo!
"""

plantilla = """\
Del siguiente texto, extrae la siguiente información:

dificultad: El curso le resulto fácil o difícil
Contesta True si fue difícil, False si no lo fue o no se indica.

material: El material cumplió con sus expectativas?
Valoralo el sentimiento sobre el material del 1 al 5.
Si no se menciona nada sobre el material devuelve -1.

calidad_precio: Extrae cualquier referencia a la calidad o precio,\
y relacionalos ofreciendo el sentimiento.

Formatea la salida como JSON con las siguientes claves:
dificultad
material
calidad_precio

text: {text}
"""

from langchain.prompts import ChatPromptTemplate

prompt_plantilla = ChatPromptTemplate.from_template(plantilla)
prompt_plantilla

messages = { 'text': valoracion }

chain = prompt_plantilla | model | StrOutputParser()

response = chain.invoke(messages)
print(response)

from langchain.output_parsers import ResponseSchema
from langchain.output_parsers import StructuredOutputParser

dificultad_schema = ResponseSchema(name="dificultad", description="¿El curso le resulto fácil o difícil? Contesta True si fue difícil, False si no lo fue o no se indica.")
material_schema = ResponseSchema(name="material", description="El material cumplió con sus expectativas? Valoralo el sentimiento sobre el material del 1 al 5. Si no se menciona nada sobre el material devuelve -1.")
calidad_precio_schema = ResponseSchema(name="calidad_precio", description="Extrae cualquier referencia a la calidad o el precio y relaciónalos ofreciendo el sentimiento.")

response_schemas = [dificultad_schema,
                    material_schema,
                    calidad_precio_schema]

procesador_salida = StructuredOutputParser.from_response_schemas(response_schemas)

format_instructions = procesador_salida.get_format_instructions()

plantilla2 = """\
Del siguiente texto, extrae la siguiente información:

dificultad: El curso le resulto fácil o difícil. Contesta True si fue difícil, False si no lo fue o no se indica.

material: El material cumplió con sus expectativas? Valoralo el sentimiento sobre el material del 1 al 5. Si no se menciona nada sobre el material devuelve -1.

calidad_precio: Extrae cualquier referencia a la calidad o precio y relacionalos ofreciendo el sentimiento.

Formatea la salida como JSON con las siguientes claves:
dificultad
material
calidad_precio

text: {text}

{format_instructions}
"""

prompt = ChatPromptTemplate.from_template(template=plantilla2)

messages = prompt.format_messages(text=valoracion, format_instructions=format_instructions)

print(messages[0].content)

response = chain.invoke(messages)

print(response)

output_dict = procesador_salida.parse(response)

output_dict