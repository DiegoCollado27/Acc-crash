{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain langchain-openai transformers"
      ],
      "metadata": {
        "id": "j8de6-E3bS92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwKvgFzo_Uk_"
      },
      "outputs": [],
      "source": [
        "\n",
        "from IPython.display import Image\n",
        "from transformers import pipeline\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "# Primero autenticamos el usuario :\n",
        "from google.colab import userdata\n",
        "secret_string = userdata.get('OPENAI_TOKEN')\n",
        "# Configurar el motor de OpenAI\n",
        "engine = \"gpt-4\"\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(temperature=1, model=engine, openai_api_key=secret_string)\n",
        "\n",
        "captioner = pipeline(\"image-to-text\",model=\"Salesforce/blip-image-captioning-base\", max_new_tokens=20)\n",
        "parser = StrOutputParser()\n",
        "\n",
        "def image2text(image):\n",
        "    text_result = captioner(image)\n",
        "    return text_result[0]['generated_text']\n",
        "\n",
        "def describir_foto(topic):\n",
        "   template = \"\"\"\n",
        "   You are a writer and story teller.\n",
        "   Your task is generate short stories from a short description. The story cannot have more than 50 words.\n",
        "   CONTEXT: {topic}\n",
        "   STORY:\n",
        "   \"\"\"\n",
        "   topic_template = PromptTemplate(template=template, input_variables=['topic'])\n",
        "   chain = ({\"topic\": RunnablePassthrough()} | topic_template | llm | parser)\n",
        "   #chain = LLMChain(llm=llm, prompt=topic_template)\n",
        "   response = chain.invoke(topic)\n",
        "   print(response)\n",
        "   return response\n",
        "\n",
        "generated_topic = image2text(\"https://huggingface.co/datasets/Narsil/image_dummy/resolve/main/parrots.png\")\n",
        "describir_foto(generated_topic)"
      ]
    }
  ]
}