{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" Ralph sat in the hot sand, touching the shell, smiling and nodding his head to the cries of admiration. Around them, the children began to settle and pay attention. It was as if they had heard for the first time the brilliant idea of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ralph', 'sat', 'in', 'the', 'hot', 'sand', ',', 'touching', 'the', 'shell', ',', 'smiling', 'and', 'nodding', 'his', 'head', 'to', 'the', 'cries', 'of', 'admiration', '.', 'Around', 'them', ',', 'the', 'children', 'began', 'to', 'settle', 'and', 'pay', 'attention', '.', 'It', 'was', 'as', 'if', 'they', 'had', 'heard', 'for', 'the', 'first', 'time', 'the', 'brilliant', 'idea', 'of']\n",
      "[('Ralph', 'NNP'), ('sat', 'VBD'), ('in', 'IN'), ('the', 'DT'), ('hot', 'JJ'), ('sand', 'NN'), (',', ','), ('touching', 'VBG'), ('the', 'DT'), ('shell', 'NN'), (',', ','), ('smiling', 'VBG'), ('and', 'CC'), ('nodding', 'VBG'), ('his', 'PRP$'), ('head', 'NN'), ('to', 'TO'), ('the', 'DT'), ('cries', 'NNS'), ('of', 'IN'), ('admiration', 'NN'), ('.', '.'), ('Around', 'IN'), ('them', 'PRP'), (',', ','), ('the', 'DT'), ('children', 'NNS'), ('began', 'VBD'), ('to', 'TO'), ('settle', 'VB'), ('and', 'CC'), ('pay', 'VB'), ('attention', 'NN'), ('.', '.'), ('It', 'PRP'), ('was', 'VBD'), ('as', 'IN'), ('if', 'IN'), ('they', 'PRP'), ('had', 'VBD'), ('heard', 'VBN'), ('for', 'IN'), ('the', 'DT'), ('first', 'JJ'), ('time', 'NN'), ('the', 'DT'), ('brilliant', 'JJ'), ('idea', 'NN'), ('of', 'IN')]\n",
      "['Ralph', 'sat', 'in', 'the', 'hot', 'sand', ',', 'touching', 'the', 'shell', ',', 'smiling', 'and', 'nodding', 'his', 'head', 'to', 'the', 'cry', 'of', 'admiration', '.', 'Around', 'them', ',', 'the', 'child', 'began', 'to', 'settle', 'and', 'pay', 'attention', '.', 'It', 'wa', 'a', 'if', 'they', 'had', 'heard', 'for', 'the', 'first', 'time', 'the', 'brilliant', 'idea', 'of']\n",
      "{'neg': 0.077, 'neu': 0.73, 'pos': 0.193, 'compound': 0.802}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/diego.collado/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokenize the text with nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "#POS tagging\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "tags = nltk.pos_tag(tokens)\n",
    "print(tags)\n",
    "\n",
    "#Lemmatization\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmas = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "print(lemmas)\n",
    "\n",
    "#sentiment analysis\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentiment = sia.polarity_scores(text)\n",
    "print(sentiment)\n",
    "\n",
    "#named entity recognition\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "entities = nltk.ne_chunk(tags)\n",
    "#print(entities)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
